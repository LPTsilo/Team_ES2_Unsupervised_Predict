{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Overview: Movie Recommendation** \n\n![](https://about.netflix.com/images/meta/netflix-symbol-black.png)","metadata":{}},{"cell_type":"markdown","source":"#### In today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.…ever wondered how Netflix, Amazon Prime, Showmax, Disney and the likes somehow know what to recommend to you?\n\n#### …it's not just a guess drawn out of the hat. There is an algorithm behind it.\n","metadata":{}},{"cell_type":"markdown","source":"# **Problem Statement**","metadata":{}},{"cell_type":"markdown","source":"#### With this context, EDSA is challenging you to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n\n#### What value is achieved through building a functional recommender system?Providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity.\n\n\n#### This dataset consists of several million 5-star ratings obtained from users of the online MovieLens movie recommendation service. The MovieLens dataset has long been used by industry and academic researchers to improve the performance of explicitly-based recommender systems, and now you get to as well!\n\n#### For this Predict, we'll be using a special version of the MovieLens dataset which has enriched with additional data, and resampled for fair evaluation purposes.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"cont\"></a>\n\n# **Table of Contents**\n\n<details>\n<summary><a href=#one>1. Importing Packages</a></summary>\n<br>\n<a href=#one.one>1.1 Importing python packages that will be used in the notebook </a>\n</details>\n\n<br>\n\n<details>\n<summary><a href=#two>2. Loading Data</a></summary>\n<br>\n<a href=#two.one>2.1 Loading the Train and Test datasets</a>\n</details>\n\n<br>\n\n<details>\n<summary><a href=#three>3. Exploratory Data Analysis (EDA)</a></summary>\n<br>\n<a href=#three.one>3.1 Why is EDA important?</a>\n<br>\n<a href=#three.two>3.2 Pandas profiling model</a>\n<br>\n<a href=#three.three>3.3 Generating a word cloud</a>\n<br>\n<a href=#three.four>3.4 Looking at the data types of the Train and Test datasets</a>\n<br>\n<a href=#three.five>3.5 Looking for null values in the Train and Test datasets</a>\n<br>\n<a href=#three.six>3.6 Investigating the distribution of categorical values</a>\n<br>\n<a href=#three.seven> 3.7  Hashtags for each sentiment</a>\n</details>\n\n<br>\n\n<details>\n<summary><a href=#four>4. Data Engineering</a></summary>\n<br>\n<a href=#four.one>4.1 A copy of each dataset </a>\n<br>\n<a href=#four.two>4.2 Function to make all text lowercase </a>\n<br>\n<a href=#four.three>4.3 Function to remove URLs </a>\n<br>\n<a href=#four.four>4.4 Removing special characters </a>\n<br>\n<a href=#four.five>4.5 Removing punctuation </a>\n<br>\n<a href=#four.six>4.6 Removing digits</a>\n<br>\n<a href=#four.seven>4.7 Removing stopwords </a>\n<br>\n<a href=#four.eight>4.8 Tokenization </a>\n<br>\n<a href=#four.nine>4.9 Lemmatization </a>\n<br>\n<a href=#four.ten>4.10 Datasets after cleaning </a>\n<br>\n<a href=#four.eleven>4.11 Analysis of data after cleaning </a>\n</details>\n\n<br>\n\n<details>\n<summary><a href=#four>5. Modeling</a></summary>\n<br>\n<a href=#five.one>5.1 Splitting the x variable from the tartget variable </a>\n<br>\n<a href=#five.two>5.2 Turning text into something the model can read </a>\n<br>\n<a href=#five.three>5.3 Splitting the data into Train and validation set </a>\n<br>\n<a href=#four.four>4.4 Training the model and evaluating the model with the validation set </a>\n<br>\n<a href=#five.five>5.5 Logistic Regression model </a>\n<br>\n<a href=#five.six>5.6 Random Forest model </a>\n<br>\n<a href=#five.seven>5.7 Naive model</a>\n<br>\n<a href=#five.eight>5.8 SVC model </a>\n<br>\n<a href=#five.nine>5.9 KNN model </a>\n<br>\n<a href=#five.ten>5.10 Test set preperation and saving the best model </a>\n<br>\n<a href=#five.eleven>5.11 Test predicitions </a>\n<br>\n<a href=#five.twelve>5.12 CSV conversion </a>\n</details>\n\n<br>\n\n<details>\n<summary><a href=#six>6. Model performance</a></summary>\n<br>\n<a href=#six.one>6.1 What is performance analysis in machine learning</a>\n<br>\n<a href=#six.two>6.2 Evaluation of model</a>\n<br>\n<a href=#six.three>6.3 Assesment of the F-1 score according to both Train and Test sets </a>\n<br>\n<a href=#six.four>6.4 Analysing the dataframe</a>\n<br>\n<a href=#six.five>6.5 Plotting the F-1 Test performance from the Test data </a>\n<br>\n<a href=#six.six>6.6 Confusion matrix of the various models </a>\n</details>\n\n<br>\n\n<details>\n<summary><a href=#six>7. Model Explanations</a></summary>\n<br>\n<a href=#seven.one>7.1 Best performing model</a>\n<br>\n<a href=#seven.two>7.2 Conclusion</a>","metadata":{}},{"cell_type":"markdown","source":" \n <a id=\"one\"></a>\n \n # **1.Importing Packages**\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| *Description: Importing Packages*|\n| :--------------------------- |\n>In this section all the packages that may be needed during our analysis and the libraries that will be used throughout the analysis and modelling will be imported. \n |\n\n---","metadata":{}},{"cell_type":"markdown","source":"### <a id=\"one.one\"></a>1.1 *Importing python packages that will be used in the notebook.*","metadata":{}},{"cell_type":"code","source":"# Libraries for data loading, data manipulation and data visulisation\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom pandas_profiling import ProfileReport\n\n\n# Libraries for data preparation and model building\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score, confusion_matrix,classification_report\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom IPython.display import Image, HTML\nimport json\nimport datetime\n\nimport nltk\nnltk.download([\"punkt\",\"stopwords\",\"wordnet\"])\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud, STOPWORDS\nimport re\n\n\nimport nltk\nfrom nltk import TreebankWordTokenizer, SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport re\nfrom textblob import TextBlob\nfrom textblob import TextBlob\nfrom nltk.tokenize import  TweetTokenizer\nSTOPWORDS = set(stopwords.words('english'))\n\nnltk.download('wordnet')\nnltk.download('stopwords')\nnltk.download('omw-1.4')\n\npd.set_option('display.max_rows', 1000)\npd.set_option('Max_colwidth', 400)\n\n# suppress cell warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Setting global constants to ensure notebook results are reproducible\n# PARAMETER_CONSTANT = ###","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:43:03.610850Z","iopub.execute_input":"2023-01-18T21:43:03.611384Z","iopub.status.idle":"2023-01-18T21:43:08.422241Z","shell.execute_reply.started":"2023-01-18T21:43:03.611280Z","shell.execute_reply":"2023-01-18T21:43:08.421295Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/edsa-movie-recommendation-predict/sample_submission.csv\n/kaggle/input/edsa-movie-recommendation-predict/movies.csv\n/kaggle/input/edsa-movie-recommendation-predict/imdb_data.csv\n/kaggle/input/edsa-movie-recommendation-predict/genome_tags.csv\n/kaggle/input/edsa-movie-recommendation-predict/genome_scores.csv\n/kaggle/input/edsa-movie-recommendation-predict/train.csv\n/kaggle/input/edsa-movie-recommendation-predict/test.csv\n/kaggle/input/edsa-movie-recommendation-predict/tags.csv\n/kaggle/input/edsa-movie-recommendation-predict/links.csv\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"two\"></a>\n\n # **2. Loading the Data**\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| *Description: Loading the data*  |\n| :--------------------------- |\n|\n>In this section the  `train.csv` and `test_with_no_lable.csv` will be loaded into the notebook.\n |","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-predict/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-predict/test.csv\")\ndf_genome_tags = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-predict/genome_tags.csv\")\ndf_genome_score = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/genome_scores.csv')\ndf_imdb = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-predict/imdb_data.csv\")\ndf_links = pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-predict/links.csv\")\ndf_movies  = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/movies.csv')\ndf_tags  = pd.read_csv('/kaggle/input/edsa-movie-recommendation-predict/tags.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:45:12.976415Z","iopub.execute_input":"2023-01-18T21:45:12.976825Z","iopub.status.idle":"2023-01-18T21:45:22.874105Z","shell.execute_reply.started":"2023-01-18T21:45:12.976794Z","shell.execute_reply":"2023-01-18T21:45:22.872893Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"two.one\"></a> 2.1 *Loading all 8 data sets.*","metadata":{}},{"cell_type":"code","source":"# Looking at the first 5 rows of the dataset\nprint (df_train.head())\n\n# Looking at how many rows and columns are in the dataset\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:22:38.839586Z","iopub.execute_input":"2023-01-18T19:22:38.839956Z","iopub.status.idle":"2023-01-18T19:22:38.851661Z","shell.execute_reply.started":"2023-01-18T19:22:38.839927Z","shell.execute_reply":"2023-01-18T19:22:38.850478Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"   userId  movieId  rating   timestamp\n0    5163    57669     4.0  1518349992\n1  106343        5     4.5  1206238739\n2  146790     5459     5.0  1076215539\n3  106362    32296     2.0  1423042565\n4    9041      366     3.0   833375837\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(10000038, 4)"},"metadata":{}}]},{"cell_type":"code","source":"# Looking at the first 5 rows of the dataset\nprint(df_test.head())\n\n# Looking at how many rows and columns are in the dataset\ndf_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:22:05.579647Z","iopub.execute_input":"2023-01-18T19:22:05.580068Z","iopub.status.idle":"2023-01-18T19:22:05.590314Z","shell.execute_reply.started":"2023-01-18T19:22:05.580033Z","shell.execute_reply":"2023-01-18T19:22:05.588878Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"   userId  movieId\n0       1     2011\n1       1     4144\n2       1     5767\n3       1     6711\n4       1     7318\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(5000019, 2)"},"metadata":{}}]},{"cell_type":"code","source":"# Looking at the first 5 rows of the dataset\nprint(df_genome_score.head())\n\n# Looking at how many rows and columns are in the dataset\ndf_genome_score.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:22:54.179612Z","iopub.execute_input":"2023-01-18T19:22:54.179993Z","iopub.status.idle":"2023-01-18T19:22:54.190490Z","shell.execute_reply.started":"2023-01-18T19:22:54.179963Z","shell.execute_reply":"2023-01-18T19:22:54.189277Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"   movieId  tagId  relevance\n0        1      1    0.02875\n1        1      2    0.02375\n2        1      3    0.06250\n3        1      4    0.07575\n4        1      5    0.14075\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(15584448, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Looking at the first 5 rows of the dataset\nprint(df_genome_tags.head())\n\n# Looking at how many rows and columns are in the dataset\ndf_genome_tags.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:22:57.359727Z","iopub.execute_input":"2023-01-18T19:22:57.360139Z","iopub.status.idle":"2023-01-18T19:22:57.371714Z","shell.execute_reply.started":"2023-01-18T19:22:57.360104Z","shell.execute_reply":"2023-01-18T19:22:57.370503Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"   tagId           tag\n0      1           007\n1      2  007 (series)\n2      3  18th century\n3      4         1920s\n4      5         1930s\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(1128, 2)"},"metadata":{}}]},{"cell_type":"code","source":"# Looking at the first 5 rows of the dataset\nprint(df_imdb.head())\n\n# Looking at how many rows and columns are in the dataset\ndf_imdb.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:23:21.670409Z","iopub.execute_input":"2023-01-18T19:23:21.670933Z","iopub.status.idle":"2023-01-18T19:23:21.686125Z","shell.execute_reply.started":"2023-01-18T19:23:21.670887Z","shell.execute_reply":"2023-01-18T19:23:21.684914Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"   movieId  \\\n0        1   \n1        2   \n2        3   \n3        4   \n4        5   \n\n                                                                                                                                                                                                                          title_cast  \\\n0                                 Tom Hanks|Tim Allen|Don Rickles|Jim Varney|Wallace Shawn|John Ratzenberger|Annie Potts|John Morris|Erik von Detten|Laurie Metcalf|R. Lee Ermey|Sarah Freeman|Penn Jillette|Jack Angel|Spencer Aste   \n1  Robin Williams|Jonathan Hyde|Kirsten Dunst|Bradley Pierce|Bonnie Hunt|Bebe Neuwirth|David Alan Grier|Patricia Clarkson|Adam Hann-Byrd|Laura Bell Bundy|James Handy|Gillian Barber|Brandon Obray|Cyrus Thiedeke|Gary Joseph Thorup   \n2                Walter Matthau|Jack Lemmon|Sophia Loren|Ann-Margret|Burgess Meredith|Daryl Hannah|Kevin Pollak|Katie Sagona|Ann Morgan Guilbert|James Andelin|Marcus Klemp|Max Wright|Cheryl Hawker|Wayne A. Evenson|Allison Levine   \n3                Whitney Houston|Angela Bassett|Loretta Devine|Lela Rochon|Gregory Hines|Dennis Haysbert|Mykelti Williamson|Michael Beach|Leon|Wendell Pierce|Donald Faison|Jeffrey D. Sams|Jazz Raycole|Brandon Hammond|Kenya Moore   \n4     Steve Martin|Diane Keaton|Martin Short|Kimberly Williams-Paisley|George Newbern|Kieran Culkin|BD Wong|Peter Michael Goetz|Kate McGregor-Stewart|Jane Adams|Eugene Levy|Rebecca Chambers|April Ortiz|Dulcy Rogers|Kathy Anthony   \n\n              director  runtime       budget  \\\n0        John Lasseter     81.0  $30,000,000   \n1   Jonathan Hensleigh    104.0  $65,000,000   \n2  Mark Steven Johnson    101.0  $25,000,000   \n3       Terry McMillan    124.0  $16,000,000   \n4       Albert Hackett    106.0  $30,000,000   \n\n                                                               plot_keywords  \n0                                           toy|rivalry|cowboy|cgi animation  \n1                                           board game|adventurer|fight|game  \n2                                                 boat|lake|neighbor|rivalry  \n3  black american|husband wife relationship|betrayal|mother son relationship  \n4                                            fatherhood|doberman|dog|mansion  \n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(27278, 6)"},"metadata":{}}]},{"cell_type":"code","source":"# Looking at the first 5 rows of the dataset\nprint(df_links .head())\n\n# Looking at how many rows and columns are in the dataset\ndf_links.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:23:41.580504Z","iopub.execute_input":"2023-01-18T19:23:41.580906Z","iopub.status.idle":"2023-01-18T19:23:41.591628Z","shell.execute_reply.started":"2023-01-18T19:23:41.580854Z","shell.execute_reply":"2023-01-18T19:23:41.590281Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"   movieId  imdbId   tmdbId\n0        1  114709    862.0\n1        2  113497   8844.0\n2        3  113228  15602.0\n3        4  114885  31357.0\n4        5  113041  11862.0\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(62423, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Looking at the first 5 rows of the dataset\nprint(df_movies .head())\n\n# Looking at how many rows and columns are in the dataset\ndf_movies.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:23:44.119646Z","iopub.execute_input":"2023-01-18T19:23:44.120315Z","iopub.status.idle":"2023-01-18T19:23:44.130221Z","shell.execute_reply.started":"2023-01-18T19:23:44.120276Z","shell.execute_reply":"2023-01-18T19:23:44.129178Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  \n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(62423, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Looking at the first 5 rows of the dataset\nprint(df_tags .head())\n\n# Looking at how many rows and columns are in the dataset\ndf_tags.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:23:48.059335Z","iopub.execute_input":"2023-01-18T19:23:48.059748Z","iopub.status.idle":"2023-01-18T19:23:48.070160Z","shell.execute_reply.started":"2023-01-18T19:23:48.059715Z","shell.execute_reply":"2023-01-18T19:23:48.068768Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"   userId  movieId               tag   timestamp\n0       3      260           classic  1439472355\n1       3      260            sci-fi  1439472256\n2       4     1732       dark comedy  1573943598\n3       4     1732    great dialogue  1573943604\n4       4     7569  so bad it's good  1573943455\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(1093360, 4)"},"metadata":{}}]},{"cell_type":"markdown","source":"<a id=\"three\"></a>\n\n# **3. Exploratory Data Analysis (EDA)**\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n|  *Description: Exploratory data analysis* |\n| :--------------------------- |\n| \n>In this section, there will be an in-depth analysis of all the variables in the dataframe. |\n\n---","metadata":{}},{"cell_type":"markdown","source":"### <a id=\"three.one\"></a> 3.1 *Why is EDA important?* \n\n&#10148; It helps to prepare the dataset for analysis. </br>\n&#10148; It allows a machine learning model to predict the dataset better. </br>\n&#10148; It gives more accurate results.  </br>\n&#10148; It also helps with choosing a better machine learning model. </br>","metadata":{}},{"cell_type":"markdown","source":"### <a id=\"three.two\"></a> 3.2  *Looking at the data types that are in the dataframes.* \n>*It can be seen there is int64, float64 and object type data*","metadata":{}},{"cell_type":"code","source":"# Train dataset\ndf_train.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test dataset\ndf_test.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Genome Score dataset\ndf_genome_score.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Genome Tags dataset\ndf_genome_tags.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imdb dataset\ndf_imdb_data.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Links dataset\ndf_links.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Movies dataset\ndf_movies.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tags dataset\ndf_tags.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"three.four\"></a> 3.4 *Looking for null values in the datasets.*\n>It can be seen that there are null values in the imdb,links and tags data sets","metadata":{}},{"cell_type":"code","source":"# Train dataset\ndf_train.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_genome_score.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_genome_tags.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imdb_data.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_links.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_movies.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tags.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"four\"></a>\n\n# **4. Data Engineering**\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n|  *Description: Data engineering*  |\n| :--------------------------- |\n| \n>In this section the dataset will be cleaned and possible new new features created - as identified in the EDA phase. |\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"### <a id=\"four.one\"></a> 4.1 *Removing Null values from imbd,links and tags datasets.*","metadata":{}},{"cell_type":"code","source":"# Removing Null values from Tags datasets\ndf_tags = df_tags.dropna()\n\n# Removing Null values from imbd datasets\ndf_links = df_links.dropna()\n\n# Removing Null values from links datasets\ndf_imdb_data = df_imdb.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:15.006529Z","iopub.execute_input":"2023-01-18T21:52:15.007037Z","iopub.status.idle":"2023-01-18T21:52:15.137130Z","shell.execute_reply.started":"2023-01-18T21:52:15.007001Z","shell.execute_reply":"2023-01-18T21:52:15.135671Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n# Checking to see if Null values have been removed from tags dataset\ndf_tags.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:25.860992Z","iopub.execute_input":"2023-01-18T21:52:25.861379Z","iopub.status.idle":"2023-01-18T21:52:25.936233Z","shell.execute_reply.started":"2023-01-18T21:52:25.861349Z","shell.execute_reply":"2023-01-18T21:52:25.934641Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"userId       0\nmovieId      0\ntag          0\ntimestamp    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Checking to see if Null values have been removed from links dataset\ndf_links.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:27.459510Z","iopub.execute_input":"2023-01-18T21:52:27.459960Z","iopub.status.idle":"2023-01-18T21:52:27.472459Z","shell.execute_reply.started":"2023-01-18T21:52:27.459925Z","shell.execute_reply":"2023-01-18T21:52:27.470946Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"movieId    0\nimdbId     0\ntmdbId     0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"\n# Checking to see if Null values have been removed from imdb dataset\ndf_imdb.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:29.579153Z","iopub.execute_input":"2023-01-18T21:52:29.579626Z","iopub.status.idle":"2023-01-18T21:52:29.598078Z","shell.execute_reply.started":"2023-01-18T21:52:29.579585Z","shell.execute_reply":"2023-01-18T21:52:29.596654Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"movieId              0\ntitle_cast       10068\ndirector          9874\nruntime          12089\nbudget           19372\nplot_keywords    11078\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"### <a id=\"four.two\"></a> 4.2 *Removing the \"|\" between words in the genres column in the movie dataset and then extracting the year from the title column*","metadata":{}},{"cell_type":"code","source":"# Removing \"|\" in the genres column from movie dataset\nlemmatizer = WordNetLemmatizer()\ngenres = df_movies[\"genres\"]\nli=[]\nfor i in range(len(genres)):\n    temp = genres[i].lower()\n    temp = temp.split(\"|\")\n    temp = [lemmatizer.lemmatize(word) for word in temp]\n    li.append(\" \".join(temp))","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:38.979761Z","iopub.execute_input":"2023-01-18T21:52:38.980708Z","iopub.status.idle":"2023-01-18T21:52:41.613163Z","shell.execute_reply.started":"2023-01-18T21:52:38.980666Z","shell.execute_reply":"2023-01-18T21:52:41.611627Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Creating a new dataset \ndf_movies_data = pd.DataFrame(li,columns=[\"genres\"],index=df_movies[\"title\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:41.615186Z","iopub.execute_input":"2023-01-18T21:52:41.615547Z","iopub.status.idle":"2023-01-18T21:52:41.624048Z","shell.execute_reply.started":"2023-01-18T21:52:41.615516Z","shell.execute_reply":"2023-01-18T21:52:41.623116Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Checking to see the \"|\" has been removed from the genres column\ndf_movies_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:43.239229Z","iopub.execute_input":"2023-01-18T21:52:43.239700Z","iopub.status.idle":"2023-01-18T21:52:43.250557Z","shell.execute_reply.started":"2023-01-18T21:52:43.239665Z","shell.execute_reply":"2023-01-18T21:52:43.249389Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                                      genres\ntitle                                                                       \nToy Story (1995)                    adventure animation child comedy fantasy\nJumanji (1995)                                       adventure child fantasy\nGrumpier Old Men (1995)                                       comedy romance\nWaiting to Exhale (1995)                                comedy drama romance\nFather of the Bride Part II (1995)                                    comedy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genres</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Toy Story (1995)</th>\n      <td>adventure animation child comedy fantasy</td>\n    </tr>\n    <tr>\n      <th>Jumanji (1995)</th>\n      <td>adventure child fantasy</td>\n    </tr>\n    <tr>\n      <th>Grumpier Old Men (1995)</th>\n      <td>comedy romance</td>\n    </tr>\n    <tr>\n      <th>Waiting to Exhale (1995)</th>\n      <td>comedy drama romance</td>\n    </tr>\n    <tr>\n      <th>Father of the Bride Part II (1995)</th>\n      <td>comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Droping genre column from movies dataset\ndf_movies = df_movies.drop('genres',axis=1)\n\n# Creatig new data frame by joining origional movies dataset to the movies dataset created above\nmovies = pd.merge(df_movies,df_movies_data,on='title', how = 'inner')\n\n# Checking the first 5 rows of the dataset\nmovies.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:49.600096Z","iopub.execute_input":"2023-01-18T21:52:49.600547Z","iopub.status.idle":"2023-01-18T21:52:49.668151Z","shell.execute_reply.started":"2023-01-18T21:52:49.600515Z","shell.execute_reply":"2023-01-18T21:52:49.667343Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                     genres  \n0  adventure animation child comedy fantasy  \n1                   adventure child fantasy  \n2                            comedy romance  \n3                      comedy drama romance  \n4                                    comedy  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>adventure animation child comedy fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>adventure child fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>comedy romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>comedy drama romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to extract year from tilte column\ndef extract_year(string):\n    string = string.strip()\n    year = re.findall(r'\\s?\\((\\d{4})\\)$', string)\n    \n    try :\n        return year[0]\n    except IndexError:\n        return \"0\"\n","metadata":{"execution":{"iopub.status.busy":"2023-01-18T21:52:52.804791Z","iopub.execute_input":"2023-01-18T21:52:52.805965Z","iopub.status.idle":"2023-01-18T21:52:52.812708Z","shell.execute_reply.started":"2023-01-18T21:52:52.805906Z","shell.execute_reply":"2023-01-18T21:52:52.811296Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Applying the function to the movies dataset\nmovies[\"year\"] = movies[\"title\"].apply(extract_year)\nmovies[\"year\"] = movies[\"year\"].astype(\"int64\")\nmovies['title'] = movies.title.str.replace('(\\(\\d\\d\\d\\d\\))', '')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the first 5 rows of the dataset after extracting the year from the title and adding year as a seperate column\nmovies.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.three\"></a> 4.3 *Removing the \"|\" between words in the title cast and plot keywords columns in the imdb dataset*","metadata":{}},{"cell_type":"code","source":"# Removing \"|\" in the title_cast column from imdb dataset\nlemmatizer = WordNetLemmatizer()\ntitle_cast = df_imdb[\"title_cast\"]\nli=[]\nfor i in range(len(title_cast)):\n    temp = genres[i].lower()\n    temp = temp.split(\"|\")\n    temp = [lemmatizer.lemmatize(word) for word in temp]\n    li.append(\" \".join(temp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing \"|\" in the plot_keywords column from imdb dataset\nlemmatizer = WordNetLemmatizer()\nplot_keywords = df_imdb[\"plot_keywords\"]\nlis=[]\nfor i in range(len(plot_keywords)):\n    temp = genres[i].lower()\n    temp = temp.split(\"|\")\n    temp = [lemmatizer.lemmatize(word) for word in temp]\n    lis.append(\" \".join(temp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a new dataset \ndf_imdb_data_ne = pd.DataFrame(li,columns=[\"tilte_cast\"],index=df_imdb[\"movieId\"])\ndf_imdb_data_new=pd.DataFrame(lis,columns=[\"plot_keywords\"],index=df_imdb[\"movieId\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:27:49.120441Z","iopub.execute_input":"2023-01-18T19:27:49.120847Z","iopub.status.idle":"2023-01-18T19:27:49.154026Z","shell.execute_reply.started":"2023-01-18T19:27:49.120812Z","shell.execute_reply":"2023-01-18T19:27:49.152450Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3792096198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creating a new dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_imdb_data_ne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tilte_cast\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_imdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"movieId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_imdb_data_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plot_keywords\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_imdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"movieId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    715\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                         \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m                     )\n\u001b[1;32m    719\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Shape of passed values is (62423, 1), indices imply (27278, 1)"],"ename":"ValueError","evalue":"Shape of passed values is (62423, 1), indices imply (27278, 1)","output_type":"error"}]},{"cell_type":"code","source":"# Checking to see the \"|\" has been removed from the title cast column\nprint(df_imdb_data_ne.head())\nprint(df_imdb_data_new.head())","metadata":{"execution":{"iopub.status.busy":"2023-01-18T19:28:09.801011Z","iopub.execute_input":"2023-01-18T19:28:09.801472Z","iopub.status.idle":"2023-01-18T19:28:09.822844Z","shell.execute_reply.started":"2023-01-18T19:28:09.801437Z","shell.execute_reply":"2023-01-18T19:28:09.821553Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2467474710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Checking to see the \"|\" has been removed from the title cast column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_imdb_data_ne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_imdb_data_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_imdb_data_ne' is not defined"],"ename":"NameError","evalue":"name 'df_imdb_data_ne' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Droping title_cast, plot_keywords and budget columns from imdb dataset\ndf_imdb_data = df_imdb_data.drop('title_cast',axis=1)\ndf_imdb_data = df_imdb_data.drop('plot_keywords',axis=1)\ndf_imdb_data = df_imdb_data.drop('budget',axis=1)\n\n# Creatig new data frame by joining origional movies data frame to the movies dataset created above\nimdb= pd.merge(pd.merge(df_imdb_data_ne,df_imdb_data_new,on='movieId'), df_imdb_data, on = 'movieId')\n\n# Checking the first 5 rows of the dataset\nimdb.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating new column for movies and their ratings by combining movie dataset and train dataset\ndf_movie_R = pd.merge(movies,df_train,on='movieId', how = 'inner')\n\n# Droping the time stamp column from the dataset\ndf_movie_R = df_movie_R.drop('timestamp', axis = 1)\n\n# Ordering the columns\ndf_movie_R = df_movie_R[['movieId','userId','title','year','genres','rating']]\n\n# Checking first 5 rows of dataset\nprint(df_movie_R.head() )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.four\"></a> 4.4  *Finding the mean rating for each title*","metadata":{}},{"cell_type":"code","source":"# This would produce means of all the ratings related to a specific title.\ndf_movie_R.groupby('title')['rating'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.five\"></a> 4.5  *Number of people who rated a soecific movie*","metadata":{}},{"cell_type":"code","source":"# Looking at number of people that gave ratings to a specific movie sorting in ascending order\n\ndf_movie_R.groupby(by='title')['rating'].count().sort_values(ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.six\"></a> 4.6  *Creating a dataframe to see visual relationship between mean rating and the number of peoplewho rated it*","metadata":{}},{"cell_type":"code","source":"# Creating a artings dataset\n\nrating_data = pd.DataFrame(df_movie_R.groupby(by='title')['rating'].mean())\n\n# Looking at first 5 rows of dataset\nrating_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a dataset with count of people who rated movie\nrating_data['No. of people Rated'] = df_movie_R.groupby(by='title')['rating'].count()\n\n# Looking at first 5 rows of dataset\nrating_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.seven\"></a> 4.7  *Looking at number of movies with 5 star reviews and movies with less than 1 star reviews*","metadata":{}},{"cell_type":"code","source":"#  Number of Movies that got 5 Star Reviews \n\nprint(\"The Number of Movies that received 5 Star Reviews :\", df_movie_R[df_movie_R['rating'] == 5]['title'].count())\nprint(\"Percentage of Movies Getting 5 Star Reviews : {0:.2f}%\".format((df_movie_R[df_movie_R['rating'] == 5]['title'].count())/(df_movie_R.shape[0])))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of Movies that got less than 1 Star Reviews \nprint(\"\\nThe Number of Movies that received less than 1 Star Reviews :\", df_movie_R[df_movie_R['rating'] <= 1]['title'].count())\nprint(\"The Percentage of Movies Getting Less than 1 Star Reviews : {0:.2f}%\".format((\n    df_movie_R[df_movie_R['rating'] <= 1]['title'].count())/(df_movie_R.shape[0])))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.eight\"></a> 4.8  *Joint plot showing number of people vs ratings*\n>This clearly shows that the Movies with ratings in the range of 3 to 4.5 has the most number of ratings. Movies with almost 5 star ratings has around 100 or 200 number of ratings to it.","metadata":{}},{"cell_type":"code","source":"sns.jointplot(x=rating_data['rating'],y=rating_data['No. of people Rated']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">The graph is bell shaped which means that the rating data is normally distributed\n","metadata":{}},{"cell_type":"code","source":"# lets look at the Distribution of Ratings across the Movies\n\nsns.displot(x=rating_data['rating'], color = 'black',kde=True,height=5)\nplt.title('Distribution of Ratings')\nplt.grid()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.ninet\"></a> 4.9  *Line Graph showing number of movies released by year*","metadata":{}},{"cell_type":"code","source":"release = df_movie_R['year'].value_counts()\nrelease = release.sort_index(ascending=True)\n\nplt.figure(figsize=(9,7))\nplt.plot(release[-11:-1])\n#plt.scatter(release[-11:-1].index, release[-11:-1].values, s=0.5*release[-11:-1].values, c='Red');\nplt.box(on=None);\nplt.xticks(rotation = 60)\nplt.xticks(release[-11:-1].index);\nplt.title('Number of Content Released by Year', fontsize=20)\nplt.xlabel('year')\nplt.ylabel('movies released');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.ten\"></a> 4.10  *Looking at run times of movies*","metadata":{}},{"cell_type":"code","source":"# Looking at the unique valuesof run time of movies\ndf_imdb_data['runtime'].unique()\n\nruntimes = []\n\nfor runtime in df_imdb_data['runtime']:\n    if runtime < 50:\n        runtimes.append('Short')\n    elif runtime < 80:\n        runtimes.append('Below minimum')\n    elif runtime < 180:\n        runtimes.append('Feature-length')\n    elif runtime < 300:\n        runtimes.append('Long')\n    elif runtime >= 300:\n        runtimes.append('VLMS')\n    else:\n        runtimes.append('No Info')\n        \ndf_imdb_data['feature_length'] = runtimes\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df_imdb_data['feature_length'], palette='rainbow')\nplt.xticks(rotation=45)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"four.eleven\"></a> 4.11  *Distribution of run time for feature length films*","metadata":{}},{"cell_type":"code","source":"feature_length = df_imdb_data[df_imdb_data['feature_length'] == 'Feature-length']\n\nplt.hist(feature_length['runtime'])\nplt.axvline((feature_length['runtime'].median()), color='k', dashes=[5,5] , linewidth=1) #Create reference line\nplt.title('Distribution of Runtime for Feature-Length Films')\nplt.xlabel('Runtime in Minutes')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"five\"></a>\n\n# **5. Modelling**\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| *Description: Modelling*  |\n| :--------------------------- |\n| \n>In this section models will be built,namley: . |\n\n---","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"<a id=\"six\"></a>\n\n# **6.Model Performance**\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n| *Description: Model performance* |\n| :--------------------------- |\n| \n>In this section the models that were built will be compared relative to their performance and the best model will be selected. |\n\n---","metadata":{}},{"cell_type":"markdown","source":"<a id=\"seven\"></a>\n\n# **7. Model Explanation**\n<a class=\"anchor\" id=\"1.1\"></a>\n<a href=#cont>Back to Table of Contents</a>\n\n---\n    \n|  *Description: Model explanation*  |\n| :--------------------------- |\n| \n>A brief explanation is given of which model preformed the best\n---\n\n![](https://imageio.forbes.com/specials-images/dam/imageserve/966248982/660x0.jpg?format=jpg&width=960)","metadata":{}},{"cell_type":"markdown","source":"### <a id=\"seven.one\"></a> 7.1 *Best Performing Model:*","metadata":{}},{"cell_type":"markdown","source":"### <a id=\"seven.two\"></a> 7.2 *Conclusion*","metadata":{}},{"cell_type":"markdown","source":"### <a id=\"seven.three\"></a> 7.3 *Refrence list*","metadata":{}}]}